# Metaphors - XR Game Development

## Project Overview
We, **Team Metaphors**, are developing an **XR game** using **Meta Quest**. Our technology stack includes **C#, Unity, and Python**. Since this is a new domain for us, we are currently in the learning phase, building prototypes to understand the fundamentals of **Game Development and Augmented Reality (AR)**.

## Current Progress
We have developed prototypes that showcase our learning and implementation of XR technologies. Below are the key aspects of our work:

### 1. Hand Tracking & Interaction in Unity
- Implemented real-time **hand tracking** using:
  - **OpenCV**
  - **MediaPipe**
  - **WebSockets**
- Streamed tracking data to **Unity** to enable interaction with virtual game components using **C# scripting**.

### 2. Marker Detection & XR Integration
- Used **OpenCV** and **MediaPipe** for:
  - **Hand tracking**
  - **Marker detection**
- Rendered **3D models** in **real-time** onto the **Ursina game engine**.
- Developed an **algorithm** to **predict and calculate gestures**, allowing:
  - **Scaling virtual objects**
  - **Pinch gestures**, similar to **Vision Pro** and **Meta Quest**.

## Next Steps
To further enhance our project and develop it specifically for **Meta Quest**, we require access to the **XR Lab**.
